{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data\n",
    "import imgaug.augmenters as iaa\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "# Model\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Read**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from directories\n",
    "def load_images_from_folder(folder, flatten):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(64,64), color_mode='grayscale')\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        # Flatten image into 1D array\n",
    "        if flatten:\n",
    "            images.append(img_array.flatten())\n",
    "        else:\n",
    "            images.append(img_array)\n",
    "        labels.append(folder)\n",
    "    return np.array(images), labels\n",
    "\n",
    "# Directory paths for bikes and cars images\n",
    "bikes_folder = 'Car-Bike-Dataset/Bike'\n",
    "cars_folder = 'Car-Bike-Dataset/Car'\n",
    "\n",
    "bike_images, bike_labels = load_images_from_folder(bikes_folder, False)\n",
    "car_images, car_labels = load_images_from_folder(cars_folder, False)\n",
    "\n",
    "all_images = np.vstack((bike_images, car_images))\n",
    "all_labels = np.array(bike_labels + car_labels)\n",
    "\n",
    "bike_images_flat, bike_labels_flat = load_images_from_folder(bikes_folder, True)\n",
    "car_images_flat, car_labels_flat = load_images_from_folder(cars_folder, True)\n",
    "\n",
    "all_images_flat = np.vstack((bike_images_flat, car_images_flat))\n",
    "all_labels_flat = np.array(bike_labels_flat + car_labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=0.2, random_state=44)\n",
    "X_train_flat, X_test_flat, y_train_flat, y_test_flat = train_test_split(all_images_flat, all_labels_flat, test_size=0.2, random_state=44)\n",
    "\n",
    "# Perform validation split\n",
    "X_val, X_train = np.split(X_train, [800])\n",
    "y_val, y_train = np.split(y_train, [800])\n",
    "\n",
    "X_val_flat, X_train_flat = np.split(X_train_flat, [800])\n",
    "y_val_flat, y_train_flat = np.split(y_train_flat, [800])\n",
    "\n",
    "# Apply fit_transform to labels to make them numeric\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_val = lb.fit_transform(y_val)\n",
    "y_test = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Augmentation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for image augmentation using imgaug\n",
    "def apply_image_augmentation(images, labels):\n",
    "    # Define an augmentation pipeline\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5),  # horizontal flips\n",
    "        # iaa.Crop(percent=(0, 0.1)),  # random crops\n",
    "        iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 0.5))),  # random Gaussian blur\n",
    "        iaa.Sometimes(0.5, iaa.AdditiveGaussianNoise(scale=(0, 0.05*255))),  # random noise\n",
    "    ], random_order=True)\n",
    "\n",
    "    augmented_images = seq(images=images)\n",
    "    augmented_labels = labels\n",
    "\n",
    "    return augmented_images, augmented_labels\n",
    "\n",
    "# Apply image augmentation to training data\n",
    "X_train_aug, y_train_aug = apply_image_augmentation(X_train, y_train)\n",
    "X_train_aug = np.vstack((X_train_aug, X_train))\n",
    "y_train_aug = np.hstack((y_train_aug, y_train))\n",
    "\n",
    "X_train_aug_flat, y_train_aug_flat = apply_image_augmentation(X_train_flat, y_train)\n",
    "X_train_aug_flat = np.vstack((X_train_aug_flat, X_train_flat))\n",
    "y_train_aug_flat = np.hstack((y_train_aug_flat, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parameter Optimization**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization For The kNN Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = range(5, 39, 2)\n",
    "knn_accuracies = []\n",
    "knn_aug_accuracies = []\n",
    "for k_value in k_values:\n",
    "    # Without Augmentation\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value)\n",
    "    knn.fit(X_train_flat, y_train)\n",
    "    accuracy = knn.score(X_val_flat, y_val)\n",
    "    knn_accuracies.append(accuracy)\n",
    "\n",
    "    # With Augmentation\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value)\n",
    "    knn.fit(X_train_aug_flat, y_train_aug)\n",
    "    accuracy = knn.score(X_val_flat, y_val)\n",
    "    knn_aug_accuracies.append(accuracy)\n",
    "\n",
    "# Best Parameters\n",
    "knn_best_param = k_values[np.argmax(knn_accuracies)]\n",
    "knn_aug_best_param = k_values[np.argmax(knn_aug_accuracies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, knn_aug_accuracies, marker=\"o\", label=\"Augmented\")\n",
    "plt.plot(k_values, knn_accuracies, marker=\"o\", label=\"Non-Augmented\")\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Number of Neighbors vs Accuracy (kNN)\")\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_param = 5\n",
    "knn_aug_best_param = 9 # DELETE\n",
    "\n",
    "def print_metrics_for_k(k_value, X_train, y_train, X_val, y_val):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_val)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    print(f\"Confusion Matrix for k={k_value}:\\n{cm}\\n\")\n",
    "\n",
    "    # Precision, Recall, and F1 Score\n",
    "    recall = recall_score(y_val, y_pred, average='macro')\n",
    "    precision = precision_score(y_val, y_pred, average='macro')\n",
    "    f1 = f1_score(y_val, y_pred, average='macro')\n",
    "\n",
    "    print(f\"Metrics for k={k_value}: Recall: {recall}, Precision: {precision}, F1 Score: {f1}\\n\")\n",
    "\n",
    "# Print metrics for the best non-augmented model\n",
    "print(\"Metrics for Non-Augmented Model\")\n",
    "print_metrics_for_k(knn_best_param, X_train_flat, y_train, X_val_flat, y_val)\n",
    "\n",
    "# Print metrics for the best augmented model\n",
    "print(\"Metrics for Augmented Model\")\n",
    "print_metrics_for_k(knn_aug_best_param, X_train_aug_flat, y_train_aug, X_val_flat, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Optimization For The SVM Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_types = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "svm_accuracies = []\n",
    "svm_aug_accuracies = []\n",
    "for kernel_type in kernel_types:\n",
    "    # Without Augmentation\n",
    "    svm = SVC(kernel=kernel_type)\n",
    "    svm.fit(X_train_flat, y_train)\n",
    "    y_pred = svm.predict(X_val_flat)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    svm_accuracies.append(accuracy)\n",
    "\n",
    "    # With Augmentation\n",
    "    svm_aug = SVC(kernel=kernel_type)\n",
    "    svm_aug.fit(X_train_aug_flat, y_train_aug)\n",
    "    y_pred = svm_aug.predict(X_val_flat)\n",
    "    accuracy_aug = accuracy_score(y_val, y_pred)\n",
    "    svm_aug_accuracies.append(accuracy_aug)\n",
    "\n",
    "# Best Parameters\n",
    "svm_best_param = kernel_types[np.argmax(svm_accuracies)]\n",
    "svm_aug_best_param = kernel_types[np.argmax(svm_aug_accuracies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(kernel_types, svm_aug_accuracies, marker=\"o\", label=\"Augmented\")\n",
    "plt.plot(kernel_types, svm_accuracies, marker=\"o\", label=\"Non-Augmented\")\n",
    "plt.xlabel(\"Kernel Types\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Kernel Type vs Accuracy (SVM)\")\n",
    "plt.xticks(kernel_types)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Optimization For The Random Forest Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 20, 50, 100, 150]\n",
    "rf_accuracies = []\n",
    "rf_aug_accuracies = []\n",
    "for n_estimator in n_estimators:\n",
    "    # Without Augmentation\n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=n_estimator)\n",
    "    rf.fit(X_train_flat, y_train)\n",
    "    y_pred = rf.predict(X_val_flat)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    rf_accuracies.append(accuracy)\n",
    "\n",
    "    # With Augmentation\n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=n_estimator)\n",
    "    rf.fit(X_train_aug_flat, y_train_aug)\n",
    "    y_pred = rf.predict(X_val_flat)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    rf_aug_accuracies.append(accuracy)\n",
    "\n",
    "# Best Parameters\n",
    "rf_best_param = n_estimators[np.argmax(rf_accuracies)]\n",
    "rf_aug_best_param = n_estimators[np.argmax(rf_aug_accuracies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators, rf_aug_accuracies, marker=\"o\", label=\"Augmented\")\n",
    "plt.plot(n_estimators, rf_accuracies, marker=\"o\", label=\"Non-Augmented\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"n_estimators vs Accuracy (Random Forest)\")\n",
    "plt.xticks(n_estimators)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Optimization For The CNN Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to Apply Layer Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_1 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "cnn_2 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "cnn_3 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "cnn_4 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = [cnn_1, cnn_2, cnn_3, cnn_4]\n",
    "model_names = [\"CNN 1\", \"CNN 2\", \"CNN 3\", \"CNN 4\"]\n",
    "\n",
    "# Lists to store accuracies for plotting\n",
    "cnn_accuracies = []\n",
    "cnn_aug_accuracies = []\n",
    "\n",
    "# Plot accuracies for each model in a separate graph\n",
    "for model, model_name in zip(models, model_names):\n",
    "    # Without augmentation\n",
    "    print(f\"\\nTraining {model_name} with non-augmented data:\")\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "    loss, accuracy = model.evaluate(X_val, y_val)\n",
    "    cnn_accuracies.append(accuracy)\n",
    "\n",
    "    # With augmentation\n",
    "    print(f\"\\nTraining {model_name} with augmented data:\")\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(X_train_aug, y_train_aug, epochs=10, validation_data=(X_val, y_val))\n",
    "    loss, accuracy = model.evaluate(X_val, y_val)\n",
    "    cnn_aug_accuracies.append(accuracy)\n",
    "\n",
    "# Best Models\n",
    "cnn_best_model = models[np.argmax(cnn_accuracies)]\n",
    "cnn_aug_best_model = models[np.argmax(cnn_aug_accuracies)]\n",
    "cnn_best_model_name = model_names[np.argmax(cnn_accuracies)]\n",
    "cnn_aug_best_model_name = model_names[np.argmax(cnn_aug_accuracies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(model_names, cnn_aug_accuracies, marker=\"o\", label=\"Augmented\")\n",
    "plt.plot(model_names, cnn_accuracies, marker=\"o\", label=\"Non-Augmented\")\n",
    "plt.xlabel(\"CNN Models\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"CNN Models vs Accuracy\")\n",
    "plt.xticks(model_names)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_best_model = cnn_4 # DELETE\n",
    "cnn_best_model_name = \"CNN 4\" # DELETE\n",
    "cnn_aug_best_model = cnn_4 # DELETE\n",
    "cnn_aug_best_model_name = \"CNN 4\" # DELETE\n",
    "\n",
    "def print_metrics_for_model(model, model_name, X_train, y_train, X_val, y_val):\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=0)\n",
    "    y_pred = model.predict(X_val).round()\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    print(f\"Confusion Matrix for model={model_name}:\\n{cm}\")\n",
    "\n",
    "    # Precision, Recall, and F1 Score\n",
    "    recall = recall_score(y_val, y_pred, average=\"binary\")\n",
    "    precision = precision_score(y_val, y_pred, average=\"binary\")\n",
    "    f1 = f1_score(y_val, y_pred, average=\"binary\")\n",
    "\n",
    "    print(f\"Metrics for model={model_name}: Recall: {recall}, Precision: {precision}, F1 Score: {f1}\\n\")\n",
    "\n",
    "# Print metrics for the best non-augmented model\n",
    "print(\"Metrics for Non-Augmented Model\")\n",
    "print_metrics_for_model(cnn_best_model, cnn_best_model_name, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Print metrics for the best augmented model\n",
    "print(\"Metrics for Augmented Model\")\n",
    "print_metrics_for_model(cnn_aug_best_model, cnn_aug_best_model_name, X_train_aug, y_train_aug, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PCA**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal\n",
    "n_components = [1, 50, 100, 250, 500, 1000, 2400]\n",
    "\n",
    "X_train_flat_pca = []\n",
    "X_val_flat_pca = []\n",
    "for components in n_components:\n",
    "    pca = PCA(n_components=components)\n",
    "    pca.fit(X_train_flat)\n",
    "    X_train_flat_pca.append(pca.transform(X_train_flat))\n",
    "    X_val_flat_pca.append(pca.transform(X_val_flat))\n",
    "\n",
    "# Augmentation\n",
    "X_train_aug_flat_pca = []\n",
    "X_val_aug_flat_pca = []\n",
    "for components in n_components:\n",
    "    pca = PCA(n_components=components)\n",
    "    pca.fit(X_train_aug_flat)\n",
    "    X_train_aug_flat_pca.append(pca.transform(X_train_aug_flat))\n",
    "    X_val_aug_flat_pca.append(pca.transform(X_val_flat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN PCA\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best kNN model with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracies_pca = []\n",
    "for i in range(len(n_components)):\n",
    "    knn = KNeighborsClassifier(n_neighbors=knn_best_param)\n",
    "    knn.fit(X_train_flat_pca[i], y_train)\n",
    "    accuracy = knn.score(X_val_flat_pca[i], y_val)\n",
    "    knn_accuracies_pca.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best kNN model with augmentation with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_aug_accuracies_pca = []\n",
    "for i in range(len(n_components)):\n",
    "    knn_aug = KNeighborsClassifier(n_neighbors=knn_aug_best_param)\n",
    "    knn_aug.fit(X_train_aug_flat_pca[i], y_train_aug)\n",
    "\n",
    "    accuracy = knn_aug.score(X_val_aug_flat_pca[i], y_val)\n",
    "    knn_aug_accuracies_pca.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(n_components, knn_aug_accuracies_pca, marker=\"o\", label=\"Augmented\")\n",
    "plt.plot(n_components, knn_accuracies_pca, marker=\"o\", label=\"Non-Augmented\")\n",
    "plt.xlabel(\"n_components\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"n_components vs Accuracy (kNN)\")\n",
    "plt.xticks(n_components, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM PCA\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best SVM model with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_accuracies_pca = []\n",
    "for i in range(len(n_components)):\n",
    "    svm = SVC(kernel=svm_best_param)\n",
    "    svm.fit(X_train_flat_pca[i], y_train)\n",
    "    y_pred = svm.predict(X_val_flat_pca[i])\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    svm_accuracies_pca.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best SVM model with augmentation with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_aug_accuracies_pca = []\n",
    "for i in range(len(n_components)):\n",
    "    svm_aug = SVC(kernel=svm_aug_best_param)\n",
    "    svm_aug.fit(X_train_aug_flat_pca[i], y_train_aug)\n",
    "    y_pred = svm_aug.predict(X_val_aug_flat_pca[i])\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    svm_aug_accuracies_pca.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(n_components, svm_aug_accuracies_pca, marker=\"o\", label=\"Augmented\")\n",
    "plt.plot(n_components, svm_accuracies_pca, marker=\"o\", label=\"Non-Augmented\")\n",
    "plt.xlabel(\"n_components\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"n_components vs Accuracy (SVM)\")\n",
    "plt.xticks(n_components, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest PCA\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracies_pca = []\n",
    "for i in range(len(n_components)):\n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=rf_best_param)\n",
    "    rf.fit(X_train_flat_pca[i], y_train)\n",
    "    y_pred = rf.predict(X_val_flat_pca[i])\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    rf_accuracies_pca.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Random Forest with Augmentation and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_aug_accuracies_pca = []\n",
    "for i in range(len(n_components)):\n",
    "    rf_aug = RandomForestClassifier(random_state=42, n_estimators=rf_aug_best_param)\n",
    "    rf_aug.fit(X_train_aug_flat_pca[i], y_train_aug)\n",
    "    y_pred = rf_aug.predict(X_val_aug_flat_pca[i])\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    rf_aug_accuracies_pca.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(n_components, rf_aug_accuracies_pca, marker=\"o\", label=\"Augmented\")\n",
    "plt.plot(n_components, rf_accuracies_pca, marker=\"o\", label=\"Non-Augmented\")\n",
    "plt.xlabel(\"n_components\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"n_components vs Accuracy (Random Forest)\")\n",
    "plt.xticks(n_components, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final Evaluation**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Train and Validation Sets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = np.vstack((X_train, X_val))\n",
    "y_final = np.hstack((y_train, y_val))\n",
    "\n",
    "X_final_flat = np.vstack((X_train_flat, X_val_flat))\n",
    "\n",
    "X_aug_final = np.vstack((X_train_aug, X_val))\n",
    "X_aug_final_flat = np.vstack((X_train_aug_flat, X_val_flat))\n",
    "y_final_aug = np.hstack((y_train_aug, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best kNN Model without Augmentation\n",
    "best_knn = KNeighborsClassifier(n_neighbors=knn_best_param)\n",
    "best_knn.fit(X_final_flat, y_final)\n",
    "best_knn_accuracy = best_knn.score(X_test_flat, y_test)\n",
    "\n",
    "# Best kNN Model with Augmentation\n",
    "best_knn_aug = KNeighborsClassifier(n_neighbors=knn_best_param)\n",
    "best_knn_aug.fit(X_aug_final_flat, y_final_aug)\n",
    "best_knn_aug_accuracy = best_knn_aug.score(X_test_flat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best SVM Model without Augmentation\n",
    "best_svm = SVC(kernel=svm_aug_best_param)\n",
    "best_svm.fit(X_final_flat, y_final)\n",
    "y_pred = best_svm.predict(X_test_flat)\n",
    "best_svm_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Best SVM Model with Augmentation\n",
    "best_svm_aug = SVC(kernel=svm_aug_best_param)\n",
    "best_svm_aug.fit(X_aug_final_flat, y_final_aug)\n",
    "y_pred = best_svm_aug.predict(X_test_flat)\n",
    "best_svm_aug_accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Random Forest Model without Augmentation\n",
    "best_rf = RandomForestClassifier(random_state=42, n_estimators=rf_best_param)\n",
    "best_rf.fit(X_final_flat, y_final)\n",
    "y_pred = best_rf.predict(X_test_flat)\n",
    "best_rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Best Random Forest Model with Augmentation\n",
    "best_rf_aug = RandomForestClassifier(random_state=42, n_estimators=rf_aug_best_param)\n",
    "best_rf_aug.fit(X_aug_final_flat, y_final_aug)\n",
    "y_pred = best_rf_aug.predict(X_test_flat)\n",
    "best_rf_aug_accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best CNN Model without Augmentation\n",
    "model = Sequential([\n",
    "Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 1)),\n",
    "MaxPooling2D((2, 2)),\n",
    "Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "MaxPooling2D((2, 2)),\n",
    "Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "MaxPooling2D((2, 2)),\n",
    "Flatten(),\n",
    "Dense(128, activation=\"relu\"),\n",
    "Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(X_final, y_final, epochs=10)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "best_cnn_accuracy = accuracy\n",
    "\n",
    "# Best CNN Model with Augmentation\n",
    "model_aug = Sequential([\n",
    "Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 1)),\n",
    "MaxPooling2D((2, 2)),\n",
    "Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "MaxPooling2D((2, 2)),\n",
    "Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "MaxPooling2D((2, 2)),\n",
    "Flatten(),\n",
    "Dense(128, activation=\"relu\"),\n",
    "Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_aug.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_aug.fit(X_aug_final, y_final_aug, epochs=10)\n",
    "loss, accuracy = model_aug.evaluate(X_test, y_test)\n",
    "best_cnn_aug_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"kNN\", \"kNN-Augmented\", \"SVM\", \"SVM-Augmented\", \"RF\", \"RF-Augmented\", \"CNN\", \"CNN-Augmented\"]\n",
    "best_accuracies = [best_knn_accuracy, best_knn_aug_accuracy, best_svm_accuracy,\n",
    "                   best_svm_aug_accuracy, best_rf_accuracy, best_rf_aug_accuracy, best_cnn_accuracy, best_cnn_aug_accuracy]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(models, best_accuracies, marker=\"o\", s=50)\n",
    "plt.xlabel(\"Best Models\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Best Models vs Accuracy\")\n",
    "plt.xticks(models, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "\n",
    "for i, (xi, yi) in enumerate(zip(models, best_accuracies)):\n",
    "    plt.text(xi, yi, f\"({yi:.4f})\", ha=\"right\", va=\"bottom\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
